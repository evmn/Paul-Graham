<html lang="en">
 <head>
  <title>
   Filters vs. Blacklists
  </title>
 </head>
 <body>
  <h1>
   Filters vs. Blacklists
  </h1>
  <p>
   September 2002
  </p>
  <p>
   The real test of any technique for eliminating spam is not how much spam
you can stop, but how much spam you can stop without stopping a significant
amount of  legitimate email.   
That is, how do you design a defense against spam so
that the error in the system is nearly all in the direction of false negatives
rather than false positives?
  </p>
  <p>
   One great advantage of
   <a href="spam.html">
    Bayesian filtering
   </a>
   is that it generates few false
positives.  This
is the main reason I prefer it to other antispam techniques, particularly
blacklisting.
  </p>
  <p>
   Simply blocking mail from any server listed on a
blacklist, as some ISPs do now, is in effect a clumsy form of filtering--
one that generates a large number of false positives, and yet only
catches a
   <a href="http://news.com.com/2100-1023-233280.html">
    small percentage
   </a>
   of spam.  Spammers seem to have
little trouble staying a step ahead of blacklists.
  </p>
  <p>
   Blacklists have been around for years.  If they worked, we'd know by now.
But according to a recent
   <a href="http://www.nwfusion.com/research/2001/0910feat.html">
    study
   </a>
   , 
the MAPS RBL, probably the best known
blacklist, catches only 24% of spam, with 34% false
positives.  It would take a conscious effort to write a content-based filter
with performance that bad.
  </p>
  <p>
   Another advantage of filtering over blacklisting is that there is less
potential for abuse.  Like other kinds of vigilantes, antispam vigilantes often 
do more
   <a href="http://www.internetnews.com/isp-news/article.php/8_1143551">
    damage
   </a>
   than the problem they're fighting.  The ACLU, the Electronic Frontier
Foundation, and Computer Professionals for Social Responsibility
(among others) have all
   <a href="http://www.peacefire.org/anti-spam/group-statement.5-17-2001.html">
    condemned
   </a>
   the practices of groups like MAPS.
  </p>
  <p>
   The problem is not just that these groups' methods are unethical.
Their unethical methods are
   <i>
    why
   </i>
   their numbers are bad.  The worst
of them will blacklist anyone who makes them mad
enough, whether their server is a source of spam or not.  
Obviously, this is not
going to generate very good filtering performance.
  </p>
  <p>
   In effect, MAPS wastes most of its bullets on civilians.
  </p>
  <p>
   Bayesian filters, because they're just programs, don't take spam personally. 
As a result, they make fewer mistakes.
  </p>
  <p>
   So if you want to fight spam, work on filters.  (Think globally, act locally.)
This approach is not only more 
effective, it's also less likely to turn you into a nut.
  </p>
  <p>
   I'm not saying it's a waste of time to keep track of spam sources.  But I do think
that whether an email comes from a server on a list of (supposed) spam
sources is just one piece of evidence among many, and probably fairly
unimportant evidence compared to the content of the email.
  </p>
  <p>
   Ultimately, I think filters will put a stop to groups like MAPS.   They only
have the power that they do because ISPs are desperate and feel
they have no alternative.  If ISPs start to do content-based filtering, 
or know that their users are, they won't have to rely on such crude
methods much longer.
  </p>
  <p>
  </p>
  <p>
   <b>
    More Info:
   </b>
  </p>
  <p>
  </p>
 </body>
</html>